{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2332307,"sourceType":"datasetVersion","datasetId":891819}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/arjav007/tb-image-classification-pytorch?scriptVersionId=233422539\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Deep Learning Based Chest X-ray Image Classification: TB Positive vs Negative**\n---\n\n### **Overview of Tuberculosis (TB)**\n\n**According to the [World Health Organization (WHO)](https://www.who.int/health-topics/tuberculosis#tab=tab_1):**\n- Tuberculosis is caused by the bacterium *Mycobacterium tuberculosis* and most commonly affects the lungs.\n- TB spreads through the air when individuals with active lung TB cough, sneeze, or spit. Inhalation of only a few germs can lead to infection.\n- Chest X-rays of patients with advanced TB often reveal **lung infections** and **cavity formation**.\n\n![TB Chest X-ray](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTWfVD5iIMNyJdAYNMayyhK6q3WbfBxynoH_w&usqp=CAU)\n\n> *Image Source: [radlines.org](https://radlines.org/X-ray_of_the_thorax_in_tuberculosis)*\n\n---\n\n### **Role of Deep Learning in Tuberculosis Detection**\n\n- **Automated Diagnosis from Chest X-rays:**  \n  Deep learning models—particularly Convolutional Neural Networks (CNNs)—can be trained to analyze chest X-ray images and classify them as TB-positive or TB-negative. This automation helps reduce the diagnostic workload for radiologists.\n\n- **Early Detection and Consistency:**  \n  Deep learning systems can detect subtle radiographic features in early-stage TB that might be missed by human experts. They also provide consistent results, unaffected by fatigue or human bias.\n\n","metadata":{}},{"cell_type":"markdown","source":"---\n# **EDA and Data Loading**","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader, random_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve\nfrom tqdm import tqdm\nimport pickle\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:02:16.351497Z","iopub.execute_input":"2025-04-11T18:02:16.351753Z","iopub.status.idle":"2025-04-11T18:02:22.674299Z","shell.execute_reply.started":"2025-04-11T18:02:16.351717Z","shell.execute_reply":"2025-04-11T18:02:22.673414Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Load Images and Labels*\n\nThe **`datasets`** module from **`torchvision`** provides a convenient utility called **`ImageFolder`** for loading image data that is organized in a specific directory structure:\n\n**root/dog/xxx.png \\\nroot/dog/xxy.png \\\nroot/dog/[...]/xxz.png \\\n.\n.\n. \\\nroot/cat/123.png \\\nroot/cat/nsdf3.png \\\nroot/cat/[...]/asd932_.png**\n\n\n\nIn this format, each subdirectory (e.g., `dog`, `cat`) represents a separate class, and all images within that folder are automatically associated with the corresponding class label.\n\nWe will use **`ImageFolder`** to load our dataset, as it automatically maps each image to its appropriate label based on the folder name.\n\nFor our task:\n- **`0` → TB Negative**\n- **`1` → TB Positive**\n\nThis makes dataset loading both efficient and intuitive for classification tasks.\n","metadata":{}},{"cell_type":"code","source":"# Define the root directory\nroot = \"/kaggle/input/TB_Chest_Radiography_Database\"\n\n# Define data transformations (modify as needed)\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to a fixed size\n    transforms.ToTensor(),          # Convert images to tensors\n    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize (modify based on dataset)\n])\n\n# Load the dataset\ndataset = datasets.ImageFolder(root, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:02:48.531253Z","iopub.execute_input":"2025-04-11T18:02:48.531575Z","iopub.status.idle":"2025-04-11T18:02:49.848053Z","shell.execute_reply.started":"2025-04-11T18:02:48.53155Z","shell.execute_reply":"2025-04-11T18:02:49.84712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Split data for train val and test dataset*","metadata":{}},{"cell_type":"code","source":"# Define split ratios\ntrain_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1  # 80% train, 10% val, 10% test\ntotal_size = len(dataset)\ntrain_size = int(train_ratio * total_size)\nval_size = int(val_ratio * total_size)\ntest_size = total_size - train_size - val_size  # Ensure all data is used\n\n# Split the dataset\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\n# Print dataset sizes\nprint(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:02:50.461885Z","iopub.execute_input":"2025-04-11T18:02:50.462244Z","iopub.status.idle":"2025-04-11T18:02:50.503114Z","shell.execute_reply.started":"2025-04-11T18:02:50.462212Z","shell.execute_reply":"2025-04-11T18:02:50.50243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Display sample images from training dataset*","metadata":{}},{"cell_type":"code","source":"# Function to denormalize and convert tensor to numpy image\ndef denormalize(img_tensor, mean=0.5, std=0.5):\n    img = img_tensor.numpy().transpose((1, 2, 0))  # (C, H, W) → (H, W, C)\n    img = img * std + mean\n    return np.clip(img, 0, 1)\n\n# Find one Normal and one Tuberculosis image\nnormal_img = None\ntb_img = None\nfor img_tensor, label in train_dataset:\n    if label == 0 and normal_img is None:\n        normal_img = (img_tensor, label)\n    elif label == 1 and tb_img is None:\n        tb_img = (img_tensor, label)\n    if normal_img and tb_img:\n        break\n\n# Prepare images and labels\nimages = [normal_img[0], tb_img[0]]\nlabels = [normal_img[1], tb_img[1]]\nclass_names = dataset.classes  # ['Normal', 'Tuberculosis']\n\n# Plot side by side\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))\nfor i in range(2):\n    img = denormalize(images[i])\n    axes[i].imshow(img.squeeze(), cmap='gray')\n    axes[i].set_title(f\"Label: {class_names[labels[i]]}\")\n    axes[i].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:02:52.87324Z","iopub.execute_input":"2025-04-11T18:02:52.873523Z","iopub.status.idle":"2025-04-11T18:02:53.475952Z","shell.execute_reply.started":"2025-04-11T18:02:52.873502Z","shell.execute_reply":"2025-04-11T18:02:53.475021Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Display Training Image distribution: TB positive and negative*","metadata":{}},{"cell_type":"code","source":"# Count the number of samples per class\nclass_counts = Counter([label for _, label in dataset.samples])\n\n# Get class names and counts\nclass_names = dataset.classes  # Class names from ImageFolder\ncounts = [class_counts[i] for i in range(len(class_names))]\n\n# Plot the class distribution\nplt.figure(figsize=(8, 6))\nplt.bar(class_names, counts, color='skyblue')\nplt.xlabel(\"Class\")\nplt.ylabel(\"Number of Images\")\nplt.title(\"Class Distribution in Dataset\")\nplt.xticks(rotation=45)  # Rotate labels if needed\nplt.grid(axis='y', linestyle=\"--\", alpha=0.7)\nplt.show()\n\ntb_neg_images = counts[0]\ntb_pos_images = counts[1]\nprint('Percent of Tuberculosis Positive : {:.2f} %'.format(100 * tb_pos_images/(tb_neg_images+tb_pos_images)))\nprint('Percent of Tuberculosis Negative : {:.2f} %'.format(100 * tb_neg_images/(tb_neg_images+tb_pos_images)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:10:54.6316Z","iopub.execute_input":"2025-04-11T18:10:54.631897Z","iopub.status.idle":"2025-04-11T18:10:54.782766Z","shell.execute_reply.started":"2025-04-11T18:10:54.631876Z","shell.execute_reply":"2025-04-11T18:10:54.781796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Handling Class Imbalance*\n\n**Sample Weighting in Loss Function (weighting the contributions of positive and negative losses to be equal)**\n\ncreate positive/negative contributors\n$$w_{pos} \\times freq_{p} = w_{neg} \\times freq_{n},$$\n$$w_{pos} = freq_{neg}$$\n$$w_{neg} = freq_{pos}$$\n\nFinal weight loss\n$$\\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \\log(f(x)) + w_{n}(1-y) \\log( 1 - f(x) ) ).$$","metadata":{}},{"cell_type":"code","source":"pos_freq = round(tb_pos_images/tb_neg_images, 2)\nneg_freq = 1 - pos_freq\n\npos_weights = neg_freq\nneg_weights = pos_freq\n\npos_contribution = pos_freq * pos_weights \nneg_contribution = neg_freq * neg_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:15:18.527168Z","iopub.execute_input":"2025-04-11T18:15:18.52747Z","iopub.status.idle":"2025-04-11T18:15:18.53149Z","shell.execute_reply.started":"2025-04-11T18:15:18.527448Z","shell.execute_reply":"2025-04-11T18:15:18.530529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert weights to torch tensor\nclass_weights = torch.tensor([neg_weights, pos_weights], dtype=torch.float32)\n\n# Define loss function\ncriterion = nn.CrossEntropyLoss(weight=class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:34:32.31849Z","iopub.execute_input":"2025-04-11T18:34:32.318843Z","iopub.status.idle":"2025-04-11T18:34:32.322989Z","shell.execute_reply.started":"2025-04-11T18:34:32.318819Z","shell.execute_reply":"2025-04-11T18:34:32.322248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training the Model\n\n*We will be using gradient accumulation to make the training more robust and faster. It helps in simulating the larger batch sizes while handling the memory contraints. More information can be found [here](https://kozodoi.me/blog/20210219/gradient-accumulation)*","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nEPOCHS = 5\nLR = 1e-5\nBATCH_SIZE = 128\nMAX_PHYSICAL_BATCH_SIZE = 16\nACCUM_ITER = BATCH_SIZE // MAX_PHYSICAL_BATCH_SIZE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:37:48.00564Z","iopub.execute_input":"2025-04-11T18:37:48.005928Z","iopub.status.idle":"2025-04-11T18:37:48.009438Z","shell.execute_reply.started":"2025-04-11T18:37:48.005907Z","shell.execute_reply":"2025-04-11T18:37:48.008656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Creating the data loaders*\n\nSince gradient accumulation will be used during training, the batch size specified in the training data loader should be less than or equal to the maximum batch size that the GPU can handle in a single forward and backward pass. This ensures that memory constraints are respected while still allowing us to simulate larger effective batch sizes through accumulation over multiple steps.","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size = MAX_PHYSICAL_BATCH_SIZE, shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = MAX_PHYSICAL_BATCH_SIZE, shuffle = False)\ntest_loader = DataLoader(test_dataset, batch_size = MAX_PHYSICAL_BATCH_SIZE, shuffle = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:37:38.815631Z","iopub.execute_input":"2025-04-11T18:37:38.815993Z","iopub.status.idle":"2025-04-11T18:37:38.819998Z","shell.execute_reply.started":"2025-04-11T18:37:38.815961Z","shell.execute_reply":"2025-04-11T18:37:38.819124Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Define Training Function*","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, optimizer, epoch, device, accum_iter):\n    model.train()\n    criterion = nn.CrossEntropyLoss()\n\n    losses = []\n    top1_acc = []\n    \n    optimizer.zero_grad()\n\n    for i, (images, target) in enumerate(train_loader):   \n        images = images.to(device)\n        target = target.to(device)\n\n        with torch.set_grad_enabled(True):\n            # compute output\n            output = model(images)\n            loss = criterion(output, target)\n\n            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n            labels = target.detach().cpu().numpy()\n\n            # measure accuracy and record loss\n            acc = accuracy_score(labels, preds)\n            losses.append(loss.item())\n            top1_acc.append(acc)\n\n            # gradient accumulation\n            loss = loss / accum_iter\n            loss.backward()\n\n            if (i + 1) % accum_iter == 0 or (i + 1 == len(train_loader)):\n                optimizer.step()\n                optimizer.zero_grad()\n\n        if (i + 1) % 200 == 0:\n            print(\n                f\"\\tTrain Epoch: {epoch} \\t\"\n                f\"Loss: {np.mean(losses):.6f} \"\n                f\"Acc@1: {np.mean(top1_acc) * 100:.6f}\"\n            )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:34:43.123558Z","iopub.execute_input":"2025-04-11T18:34:43.123852Z","iopub.status.idle":"2025-04-11T18:34:43.129806Z","shell.execute_reply.started":"2025-04-11T18:34:43.12383Z","shell.execute_reply":"2025-04-11T18:34:43.128966Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Define Evaluation Function*","metadata":{}},{"cell_type":"code","source":"def evaluate(model, test_loader, device, num_classes=2):\n    model.eval()\n    criterion = nn.CrossEntropyLoss()\n    losses = []\n    top1_acc = []\n    all_preds = []\n    all_labels = []\n    all_probs = []\n\n    with torch.no_grad():\n        for images, target in test_loader:\n            images = images.to(device)\n            target = target.to(device)\n\n            output = model(images)\n            loss = criterion(output, target)\n            probs = torch.softmax(output, dim=1).cpu().numpy()\n            preds = np.argmax(probs, axis=1)\n            labels = target.cpu().numpy()\n\n            acc = accuracy_score(labels, preds)\n            losses.append(loss.item())\n            top1_acc.append(acc)\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            all_probs.extend(probs)\n\n    top1_avg = np.mean(top1_acc)\n    mean_loss = np.mean(losses)\n    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n    auc = roc_auc_score(all_labels, all_probs, multi_class=\"ovr\") if num_classes > 2 else roc_auc_score(all_labels, [p[1] for p in all_probs])\n\n    return top1_avg, f1, auc, all_labels, all_probs, mean_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:44:14.618137Z","iopub.execute_input":"2025-04-11T18:44:14.618546Z","iopub.status.idle":"2025-04-11T18:44:14.627688Z","shell.execute_reply.started":"2025-04-11T18:44:14.618516Z","shell.execute_reply":"2025-04-11T18:44:14.626855Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Training Loop*","metadata":{}},{"cell_type":"code","source":"name = 'DenseNet121'\nprint(f\"The Model is: {name}\")\n\n# Call the model\nmodel = models.densenet121(num_classes=2)\nmodel = model.to(device)\n\n# Call the optimizer\noptimizer = optim.RMSprop(model.parameters(), lr=LR) \n\n# Training the model\nfor epoch in range(EPOCHS):\n    train(model, train_loader, optimizer, epoch + 1, device, ACCUM_ITER)\n    print(f\"Evaluating the model\")\n    top1_avg, f1, auc_score, all_labels, all_probs, mean_loss = evaluate(model, val_loader, device)\n    print(\n        f\"\\tVal set:\"\n        f\" Loss: {mean_loss:.6f} \"\n        f\" Acc: {top1_avg * 100:.6f} \"\n        f\" F1: {f1:.6f} \"\n        f\" AUC: {auc_score:.6f} \"\n    )\n    print(f\"-------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:57:27.501556Z","iopub.execute_input":"2025-04-11T18:57:27.501854Z","iopub.status.idle":"2025-04-11T19:01:56.400299Z","shell.execute_reply.started":"2025-04-11T18:57:27.501833Z","shell.execute_reply":"2025-04-11T19:01:56.39938Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Evaluating the Model on Test Data**\n\nTo assess the model’s performance on unseen data, we use three important evaluation metrics:\n\n1. **Accuracy –** Measures the overall correctness of the model by calculating the proportion of total predictions that were correct.\n2. **F1 Score –** Provides a balance between precision and recall, especially useful when dealing with imbalanced datasets, as it considers both false positives and false negatives.\n3. **AUC-ROC Score –** Evaluates the model’s ability to distinguish between classes by measuring the trade-off between the true positive rate and the false positive rate across different threshold values.\n\nTogether, these metrics offer a comprehensive view of the model’s effectiveness in handling the classification task.","metadata":{}},{"cell_type":"code","source":"# Evaluating the model\ntop1_avg, f1, auc_score, all_labels, all_probs, mean_loss = evaluate(model, test_loader, device)\nprint(\n        f\" Val set:\"\n        f\" Loss: {mean_loss:.6f} \"\n        f\" Acc: {top1_avg * 100:.6f} \"\n        f\" F1: {f1:.6f} \"\n        f\" AUC: {auc_score:.6f} \"\n    )\nprint(f\"-------------------------------------\")\n\n# Plot ROC Curve for this batch size\nplt.figure(figsize=(10, 8))\nfpr, tpr, _ = roc_curve(all_labels, [p[1] for p in all_probs])  \nplt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.title(f\"AUC ROC Curve\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T19:02:24.22519Z","iopub.execute_input":"2025-04-11T19:02:24.22553Z","iopub.status.idle":"2025-04-11T19:02:29.612766Z","shell.execute_reply.started":"2025-04-11T19:02:24.225509Z","shell.execute_reply":"2025-04-11T19:02:29.612058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n# **Conclusion**\n\nThis notebook demonstrated a deep learning-based approach to classify chest X-ray images for Tuberculosis (TB) detection. By leveraging Convolutional Neural Networks and appropriate evaluation metrics, we were able to build an effective model that can aid in the early and automated diagnosis of TB.\n\nWhile the model demonstrates strong performance and is well-suited for the task at hand, there's always room for further improvement. There are several strategies that could be explored to further enhance its effectiveness:\n\n1. **Reduce the Batch Size** – A smaller batch size might help the model generalize better by introducing more gradient noise during training, which can lead to improved performance on unseen data.\n2. **Increase the Number of Epochs with a Learning Rate Scheduler** – Training the model for more epochs while using a learning rate scheduler can allow it to learn more thoroughly without overfitting, by gradually reducing the learning rate as training progresses.\n3. **Experiment with Larger Models** – Trying architectures with more parameters and deeper layers could potentially improve performance, especially if the task benefits from higher model capacity.\n4. **Perform Hyperparameter Tuning** – Systematically optimizing hyperparameters (like learning rate, dropout rate, and optimizer settings) could lead to better model performance by finding the most effective configuration\n\nAutomating TB detection using Deep Learning not only supports radiologists but also has the potential to make healthcare more accessible and scalable—especially in resource-limited settings.\n\n**Thank you for exploring this notebook!**\n","metadata":{}}]}